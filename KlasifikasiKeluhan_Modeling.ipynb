{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ekstraksi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(range(0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       atheos mungkin perempuan bj merah yg paling li...\n",
      "1       kang teman timpa pohn dijln sangkuriang dpn po...\n",
      "2       di tribun jabar biasa suka post agenda kang em...\n",
      "3       rt lapor pak lampu terang jalan depan kampus l...\n",
      "4       bapakibu mau tanya kalo pelihara taman2 yg ban...\n",
      "5       pa tempat kerja tgl 25 tetep masuk gimana atur...\n",
      "6       00106700466 punten minggu air pdam alir mohon ...\n",
      "7                  rt anak sma tahu curi hem bip hari pak\n",
      "8       nyata warga yg konfirm pdamkatanya air alir la...\n",
      "9       kang jalan muararajeun baru baru bulan dibener...\n",
      "10      rt didinyamah kieu bosss maha pak daerah sapha...\n",
      "11      pak punten marahin motor yg ga pake spakbor be...\n",
      "12              hatur nuhun dbmp lampu jlmerdeka atos sae\n",
      "13      kalo mau batas kendara yg feasible laku segera...\n",
      "14      rt pak punten marahin motor yg ga pake spakbor...\n",
      "15      pak tadi habis kebun binatang bersih kurang or...\n",
      "16      rt lapor pak mobil ni 2x buang sampah pinggir ...\n",
      "17      bonbin bandung kurang awat kasi sama hewan hew...\n",
      "18      pak sy pnya saran angkot 08 antapani yg coklat...\n",
      "19      rt lapor pak mobil ni 2x buang sampah pinggir ...\n",
      "20      pak sya lg mau pulang naek diangkot cheum lede...\n",
      "21      kotabdg seperti buat jlnan macet adlah prmptan...\n",
      "22      kalau macet begini lihat depan apa macet angko...\n",
      "23      saurwargi tolg ad orang wanita d jl eikman tia...\n",
      "24      jabar kotabdg dukung rencana badan hukum angko...\n",
      "25      rt bdg saurwargi tolg ad orang wanita d jl eik...\n",
      "26      atheos he he perempuan belum dh tanya sama rk ...\n",
      "27      punten baru denger berita apa tertib modus amb...\n",
      "28      min kalau lihat foto bawah benar jl cemara mil...\n",
      "29      rt min kalau lihat foto bawah benar jl cemara ...\n",
      "                              ...                        \n",
      "7497    forever orang baik niat baik yg bangsa butuh a...\n",
      "7498    jual laser ga ganggu sm sekaliga yg celakabyk ...\n",
      "7499    kangtd mlm jln cikutra orng papua pd ngamuk bw...\n",
      "7500                rt tertib pkl panjang jlremartadinata\n",
      "7501               rt 281 urc pju baik lampu pju jl karya\n",
      "7502         rt 281 urc pju baik lampu pju jl gunung batu\n",
      "7503    pak kemarin berita jomlo bandung yg minta bant...\n",
      "7504              rt lalinbdg 1816 jl moch toha banjir cc\n",
      "7505          rt gimana dialog kalau larang bicara publik\n",
      "7506    ada solusi lebih simpel murah atas macet proye...\n",
      "7507    jual atas trotoar depan ptinti jlmochtohabersi...\n",
      "7508    rt permanadp jual atas trotoar depan ptinti jl...\n",
      "7509    di katamso dpn kursus bahasa sptnya bocor pipa...\n",
      "7510    rt di katamso dpn kursus bahasa sptnya bocor p...\n",
      "7511    waspada dukung tdk tulus dr org2 yg tdk suka i...\n",
      "7512    dapat informasi air keluar asal bak kontrol te...\n",
      "7513    bagus bangun yg langgar dpt sanksi hanya utk l...\n",
      "7514    kotabdg ngalonyeng keneh teu kapokkeun geuning...\n",
      "7515    pa tong nyalon ka jakarta atuh pa warga bdg ny...\n",
      "7516    makin speechless sama bandungjuara amp jalan r...\n",
      "7517          kirain spanduk simpatisan isis larang masuk\n",
      "7518                                   kpn pak baik mulai\n",
      "7519                 tim urc gedebage msh jl bunga bakung\n",
      "7520    kotabdg oia klo ga salah tadi lampu merah empa...\n",
      "7521    jadi gubernur dki jakarta dikitdikit kena krit...\n",
      "7522    rt 98 pa tong nyalon ka jakarta atuh pa warga ...\n",
      "7523    whattdi jabar msh byk daerah potensi yg blm ja...\n",
      "7524    nah maksudnyakrn blm serahterima pdhl jalan ru...\n",
      "7525    buka twitter muncul promote ginian gimana atuh...\n",
      "7526    rt kang angkot jadi timebased pake halte mungk...\n",
      "Name: TweetProcessed, Length: 7527, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/keluhan_processed.csv', encoding='ISO-8859-1')\n",
    "X = data['TweetProcessed']\n",
    "y = data['Keluhan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vektor dokumen (X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/vectorizer/vec1.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "X1 = vectorizer.fit_transform(X)\n",
    "dump(vectorizer, 'model/vectorizer/vec1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vektor TF IDF tanpa normalisasi (X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/vectorizer/vec2.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,2), norm=None)\n",
    "X2 = vectorizer.fit_transform(X)\n",
    "dump(vectorizer, 'model/vectorizer/vec2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vektor TF IDF dengan normalisasi (X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/vectorizer/vec3.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "X3 = vectorizer.fit_transform(X)\n",
    "dump(vectorizer, 'model/vectorizer/vec3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Modeling_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size=0.4, random_state=0)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size=0.4, random_state=1)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y, test_size=0.4, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Decision tree model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train: X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.6994652406417112\n",
      "Accuracy:  0.8133510461640651\n"
     ]
    }
   ],
   "source": [
    "tree_classifier.fit(X1_train, y1_train)\n",
    "dump(tree_classifier, 'model/tree/tree1.joblib')\n",
    "\n",
    "prediction = tree_classifier.predict(X1_test)\n",
    "print('F1 score: ', f1_score(prediction, y1_test))\n",
    "print('Accuracy: ', accuracy_score(prediction, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train: X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7233160621761657\n",
      "Accuracy:  0.8226502822982398\n"
     ]
    }
   ],
   "source": [
    "tree_classifier.fit(X2_train, y2_train)\n",
    "dump(tree_classifier, 'model/tree/tree2.joblib')\n",
    "\n",
    "prediction = tree_classifier.predict(X2_test)\n",
    "print('F1 score: ', f1_score(prediction, y2_test))\n",
    "print('Accuracy: ', accuracy_score(prediction, y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train: X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7170809095716552\n",
      "Accuracy:  0.8223181667220193\n"
     ]
    }
   ],
   "source": [
    "tree_classifier.fit(X3_train, y3_train)\n",
    "dump(tree_classifier, 'model/tree/tree3.joblib')\n",
    "\n",
    "prediction = tree_classifier.predict(X3_test)\n",
    "print('F1 score: ', f1_score(prediction, y3_test))\n",
    "print('Accuracy: ', accuracy_score(prediction, y3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _SVM model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = LinearSVC(random_state=0, max_iter=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train: X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7447033898305085\n",
      "Accuracy:  0.8399202922617071\n"
     ]
    }
   ],
   "source": [
    "svm_classifier.fit(X1_train, y1_train)\n",
    "dump(svm_classifier, 'model/svm/svm1.joblib')\n",
    "\n",
    "prediction = svm_classifier.predict(X1_test)\n",
    "print('F1 score: ', f1_score(prediction, y1_test))\n",
    "print('Accuracy: ', accuracy_score(prediction, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train: X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7992370052455889\n",
      "Accuracy:  0.8601793424111591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "svm_classifier.fit(X2_train, y2_train)\n",
    "dump(svm_classifier, 'model/svm/svm2.joblib')\n",
    "\n",
    "prediction = svm_classifier.predict(X2_test)\n",
    "print('F1 score: ', f1_score(prediction, y2_test))\n",
    "print('Accuracy: ', accuracy_score(prediction, y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train: X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7937438905180841\n",
      "Accuracy:  0.8598472268349385\n"
     ]
    }
   ],
   "source": [
    "svm_classifier.fit(X3_train, y3_train)\n",
    "dump(svm_classifier, 'model/svm/svm3.joblib')\n",
    "\n",
    "prediction = svm_classifier.predict(X3_test)\n",
    "print('F1 score: ', f1_score(prediction, y3_test))\n",
    "print('Accuracy: ', accuracy_score(prediction, y3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _MLP model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50, 50), random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train: X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7086614173228346\n",
      "Accuracy:  0.8279641315177682\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier.fit(X1_train, y1_train)\n",
    "dump(mlp_classifier, 'model/mlp/mlp1.joblib')\n",
    "\n",
    "prediction = mlp_classifier.predict(X1_test)\n",
    "print('F1 score: ', f1_score(prediction, y1_test))\n",
    "print('Accuracy: ', accuracy_score(prediction, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train: X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8102658111824015\n",
      "Accuracy:  0.8625041514447027\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier.fit(X2_train, y2_train)\n",
    "dump(mlp_classifier, 'model/mlp/mlp2.joblib')\n",
    "\n",
    "prediction = mlp_classifier.predict(X2_test)\n",
    "print('F1 score: ', f1_score(prediction, y2_test))\n",
    "print('Accuracy: ', accuracy_score(prediction, y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train: X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7983034872761545\n",
      "Accuracy:  0.8578545333776154\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier.fit(X3_train, y3_train)\n",
    "dump(mlp_classifier, 'model/mlp/mlp3.joblib')\n",
    "\n",
    "prediction = mlp_classifier.predict(X3_test)\n",
    "print('F1 score: ', f1_score(prediction, y3_test))\n",
    "print('Accuracy: ', accuracy_score(prediction, y3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
